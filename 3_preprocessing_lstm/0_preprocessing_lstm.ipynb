{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "'''\n",
    "preprocessing (LSTM)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** import package **\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pathlib\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from _utils.preprocessing_lstm import *\n",
    "from _utils.customlogger import customlogger as CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** loading config **\n",
    "with open('./../{}'.format(\"config.json\")) as file:\n",
    "    cfg = json.load(file)\n",
    "\n",
    "with open('./../{}'.format(\"config_params.json\")) as file:\n",
    "    params = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** loading info **\n",
    "current_dir = pathlib.Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "current_date = cfg[\"working_date\"]\n",
    "curr_file_name = os.path.splitext(os.path.basename(os.path.abspath('')))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **create Logger**\n",
    "log = CL(\"custom_logger\")\n",
    "pathlib.Path.mkdir(pathlib.Path('{}/_log/'.format(parent_dir)), mode=0o777, parents=True, exist_ok=True)\n",
    "log = log.create_logger(file_name=\"../_log/{}.log\".format(curr_file_name), mode=\"a\", level=\"DEBUG\")  \n",
    "log.debug('start {}'.format(curr_file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampling_4w(df):\n",
    "    return df.groupby('unique_id').apply(lambda x : x.set_index('concept_date').resample('7d').last().reset_index()).reset_index(drop=True)\n",
    "\n",
    "def get_time_stamp(df):\n",
    "    return int(len(df)/len(df.unique_id.unique()))\n",
    "\n",
    "def remove_special_characters(str):\n",
    "    import re\n",
    "    return re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]','', str)\n",
    "\n",
    "def save_single_concept_bar_plot(dir, df, concept_id, concept_name):\n",
    "    import seaborn as sns\n",
    "    import textwrap\n",
    "    fig=plt.figure()\n",
    "    plt.rcParams['figure.figsize'] = [7.00, 3.50]\n",
    "    plt.rcParams['figure.autolayout'] = True\n",
    "    ax = sns.boxplot(data=df, x=\"sequence\", y=concept_id, hue='label')\n",
    "        # showcaps=False,                     # 박스 상단 가로라인 보이지 않기\n",
    "        # whiskerprops={'linewidth':0},       # 박스 상단 세로 라인 보이지 않기 \n",
    "        # showfliers=True                     # 박스 범위 벗어난 아웃라이어 표시하지 않기\n",
    "    concept_name_short = textwrap.shorten(concept_name, width=60, placeholder=\"...\")\n",
    "    ax.set(title='{} ( {} )'.format(concept_name_short, concept_id))\n",
    "    timestamp = get_time_stamp(df)\n",
    "    ax.set_xticklabels(['t - {}w'.format(i) for i in range(timestamp, 0, -1)])\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('value')\n",
    "    \n",
    "    plt.savefig('{}/{}.png'.format(dir, concept_name), format='png',\n",
    "            dpi=300, facecolor='white', transparent=True,  bbox_inches='tight')\n",
    "    plt.show()\n",
    "        \n",
    "def save_all_features(dir, df, concept_dict):\n",
    "    concept_id_list = list(set(df.columns) & set(concept_dict.keys()))\n",
    "    for concept_id in concept_id_list:\n",
    "        concept_name = remove_special_characters(concept_dict[concept_id])\n",
    "        save_single_concept_bar_plot(dir, df, concept_id, concept_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTask(outcome_name):\n",
    "    # In[ ]:\n",
    "    log.debug(\"{}\".format(outcome_name))\n",
    "    # input file path\n",
    "    importsql_output_dir = pathlib.Path('{}/data/{}/importsql/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "    # output file path\n",
    "    output_dir = pathlib.Path('{}/data/{}/preprocess_lstm/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "    pathlib.Path.mkdir(output_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "    # output file path (features)\n",
    "    output_result_dir = pathlib.Path('{}/result/{}/preprocess_lstm/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "    pathlib.Path.mkdir(output_result_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "\n",
    "    # In[ ]:\n",
    "    # @load data\n",
    "    meas_df = pd.read_csv('{}/{}_meas_df.txt'.format(importsql_output_dir, outcome_name), low_memory=False)\n",
    "    drug_df = pd.read_csv('{}/{}_drug_df.txt'.format(importsql_output_dir, outcome_name), low_memory=False)\n",
    "    proc_df = pd.read_csv('{}/{}_proc_df.txt'.format(importsql_output_dir, outcome_name), low_memory=False)\n",
    "    cond_df = pd.read_csv('{}/{}_cond_df.txt'.format(importsql_output_dir, outcome_name), low_memory=False)\n",
    "\n",
    "    # @fill concept_value\n",
    "    drug_df['concept_value'] = 1 # temp code\n",
    "    proc_df['concept_value'] = 1\n",
    "    cond_df['concept_value'] = 1\n",
    "\n",
    "    # @use only necessary columns\n",
    "    common_cols = ['person_id', 'age', 'sex', 'cohort_start_date', 'first_abnormal_date', 'concept_date', 'concept_id', 'concept_name', 'concept_value', 'concept_domain', 'label']\n",
    "\n",
    "    meas_df = meas_df[common_cols]\n",
    "    drug_df = drug_df[common_cols]\n",
    "    proc_df = proc_df[common_cols]\n",
    "    cond_df = cond_df[common_cols]\n",
    "\n",
    "    print(len(meas_df), len(drug_df), len(proc_df), len(cond_df), (len(meas_df) + len(drug_df) + len(proc_df) + len(cond_df)))\n",
    "\n",
    "    # @valid data processing for cohorts.\n",
    "    meas_df = cohortConditionSetting(meas_df, pre_observation_period=60, post_observation_peroid=60)\n",
    "    drug_df = cohortConditionSetting(drug_df, pre_observation_period=60, post_observation_peroid=60)\n",
    "    proc_df = cohortConditionSetting(proc_df, pre_observation_period=60, post_observation_peroid=60)\n",
    "    cond_df = cohortConditionSetting(cond_df, pre_observation_period=60, post_observation_peroid=60)\n",
    "\n",
    "    all_domain_vars_df = pd.concat([meas_df, drug_df, proc_df, cond_df], axis=0, ignore_index=True)\n",
    "    print('label 1 : ', len(all_domain_vars_df[all_domain_vars_df['label']==1].person_id.unique()))\n",
    "    print('label 0 : ', len(all_domain_vars_df[all_domain_vars_df['label']==0].person_id.unique()))\n",
    "\n",
    "    # def average_duration_of_adverse_events(df):\n",
    "    #     df = df[['person_id', 'cohort_start_date', 'first_abnormal_date']].drop_duplicates() #.subject_id.unique()\n",
    "    #     df['c_f'] = df['first_abnormal_date'] - df['cohort_start_date']\n",
    "    #     print(df['c_f'].describe())\n",
    "    #     return df['c_f'].mean().days\n",
    "\n",
    "    # ndays = average_duration_of_adverse_events(cond_df)\n",
    "    # print(ndays)\n",
    "\n",
    "    # person_df = meas_df[[\"person_id\", \"label\"]].drop_duplicates()\n",
    "    # print(person_df.label.value_counts())\n",
    "    # person_df = drug_df[[\"person_id\", \"label\"]].drop_duplicates()\n",
    "    # print(person_df.label.value_counts())\n",
    "    # person_df = proc_df[[\"person_id\", \"label\"]].drop_duplicates()\n",
    "    # print(person_df.label.value_counts())\n",
    "    # person_df = cond_df[[\"person_id\", \"label\"]].drop_duplicates()\n",
    "    # print(person_df.label.value_counts())\n",
    "    \n",
    "    # ---------------------- check features ----------------------------\n",
    "    concept_list = []\n",
    "    nCaseInTotal = len(all_domain_vars_df.loc[all_domain_vars_df['label']==1,'person_id'].unique())\n",
    "    nControlInTotal =len(all_domain_vars_df.loc[all_domain_vars_df['label']==0,'person_id'].unique())\n",
    "\n",
    "    meas_df = meas_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "    drug_df = drug_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "    cond_df = cond_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "    proc_df = proc_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "\n",
    "    meas_concept_df = meas_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate_concept(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "    drug_concept_df = drug_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate_concept(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "    cond_concept_df = cond_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate_concept(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "    proc_concept_df = proc_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate_concept(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "\n",
    "    meas_concept_df['concept_domain'] = 'meas'\n",
    "    drug_concept_df['concept_domain'] = 'drug'\n",
    "    cond_concept_df['concept_domain'] = 'proc'\n",
    "    proc_concept_df['concept_domain'] = 'cond'\n",
    "    \n",
    "    all_domain_concept_df = pd.concat([meas_concept_df, drug_concept_df, cond_concept_df, proc_concept_df], axis=0, ignore_index=True)\n",
    "    all_domain_concept_df.to_csv('{}/{}_feature_2.csv'.format(output_result_dir, outcome_name), header=True, index=True)\n",
    "    # -------------------------------------------------------------------\n",
    "    \n",
    "    # @variable selection\n",
    "    meas_vars_df = variant_selection_paired_t_test(meas_df)\n",
    "    drug_vars_df = variant_selection_mcnemar(drug_df)\n",
    "    proc_vars_df = variant_selection_mcnemar(proc_df)\n",
    "    cond_vars_df = variant_selection_mcnemar(cond_df)\n",
    "\n",
    "    # @variable selection (Top 30 based on p Value)\n",
    "    #pd.options.display.precision = 3\n",
    "    meas_vars_df = meas_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True).head(30)\n",
    "    drug_vars_df = drug_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True).head(30)\n",
    "    cond_vars_df = cond_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True).head(30)\n",
    "    proc_vars_df = proc_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True).head(30)\n",
    "    print(len(meas_vars_df), len(drug_vars_df), len(proc_vars_df), len(cond_vars_df))\n",
    "    \n",
    "    meas_vars_df['concept_domain'] = 'meas'\n",
    "    drug_vars_df['concept_domain'] = 'drug'\n",
    "    cond_vars_df['concept_domain'] = 'proc'\n",
    "    proc_vars_df['concept_domain'] = 'cond'\n",
    "    all_domain_vars_df = pd.concat([meas_vars_df, drug_vars_df, cond_vars_df, proc_vars_df], axis=0, ignore_index=True)\n",
    "    # @variable selection (save)\n",
    "    all_domain_vars_df.to_csv('{}/{}_feature.csv'.format(output_result_dir, outcome_name), header=True, index=True)\n",
    "    # all_domain_vars_df = pd.read_csv('{}/{}_{}_feature.csv'.format(output_result_dir, outcome_name), index_col=False) #check\n",
    "\n",
    "    # @Extract only selected concepts from data frame\n",
    "    def extractSelectedConceptID(domain_df, concept_id_list):\n",
    "        extract_domain_df = domain_df[domain_df['concept_id'].isin(concept_id_list)]\n",
    "        print(len(concept_id_list), len(domain_df), len(extract_domain_df))\n",
    "        return extract_domain_df\n",
    "\n",
    "    meas_df2 = extractSelectedConceptID(meas_df, meas_vars_df.concept_id.unique())\n",
    "    drug_df2 = extractSelectedConceptID(drug_df, drug_vars_df.concept_id.unique())\n",
    "    proc_df2 = extractSelectedConceptID(proc_df, proc_vars_df.concept_id.unique())\n",
    "    cond_df2 = extractSelectedConceptID(cond_df, cond_vars_df.concept_id.unique())\n",
    "\n",
    "    # meas_df2 = extractSelectedConceptID(meas_df2, meas_common_features.concept_id.unique())\n",
    "    # drug_df2 = extractSelectedConceptID(drug_df2, drug_common_features.concept_id.unique())\n",
    "    # proc_df2 = extractSelectedConceptID(proc_df2, proc_common_features.concept_id.unique())\n",
    "    # cond_df2 = extractSelectedConceptID(cond_df2, cond_common_features.concept_id.unique())\n",
    "\n",
    "    all_domain_df = pd.concat([meas_df2, drug_df2, proc_df2, cond_df2], axis=0, ignore_index=True)\n",
    "    # all_domain_df.drop(all_domain_df[all_domain_df['concept_domain']=='drug'].index, inplace=True)\n",
    "\n",
    "    pivot_data = pivotting(all_domain_df)\n",
    "    # pivot_data = pivot_data.query(\"concept_date <= cohort_start_date\")\n",
    "    # pivot_data = pivot_data.sort_values(by=[\"person_id\", \"concept_date\"], axis=0, ascending=[True, False]).reset_index(drop=True)\n",
    "    # pivot_data = pivot_data.drop_duplicates(subset=['person_id'], keep = 'first')\n",
    "    # pivot_data = pivot_data.fillna(0)\n",
    "\n",
    "    drop_cols = []\n",
    "    for col in pivot_data.columns:\n",
    "        if (len(pivot_data[pivot_data[col].notnull()])/len(pivot_data[col]) < 0.3):\n",
    "            drop_cols.append(col)\n",
    "    print(drop_cols)\n",
    "    pivot_data = pivot_data.drop(drop_cols, axis='columns')\n",
    "\n",
    "    domain_ids={}\n",
    "    domain_ids['meas'] = np.setdiff1d(meas_df2.concept_id.unique(), drop_cols)\n",
    "    domain_ids['drug'] = np.setdiff1d(drug_df2.concept_id.unique(), drop_cols)\n",
    "    domain_ids['proc'] = np.setdiff1d(proc_df2.concept_id.unique(), drop_cols)\n",
    "    domain_ids['cond'] = np.setdiff1d(cond_df2.concept_id.unique(), drop_cols)\n",
    "\n",
    "    # -------- time series data ---------\n",
    "    interpolate_df = day_sequencing_interpolate(pivot_data, domain_ids, OBP=params[\"windowsize\"])\n",
    "\n",
    "    label_1 = interpolate_df[interpolate_df['label']==1]\n",
    "    label_0 = interpolate_df[interpolate_df['label']==0]\n",
    "\n",
    "    rolled_label1_d = shift_rolling_window(label_1, OBP=params[\"windowsize\"], nShift=params[\"shift\"], uid_index=1)\n",
    "    rolled_label0_d = label_0_fitting(label_0, OBP=params[\"windowsize\"], nShift=params[\"shift\"], uid_index=(rolled_label1_d.unique_id.max()+1))\n",
    "\n",
    "    # label 0 + label 1\n",
    "    concat_df = pd.concat([rolled_label1_d, rolled_label0_d], sort=False)\n",
    "    concat_df = concat_df.sort_values(['unique_id', 'concept_date'])\n",
    "    # -------- time series data ---------\n",
    "\n",
    "    concept_dict = dict(zip(all_domain_df.concept_id, all_domain_df.concept_name))\n",
    "    concat_4w_df = resampling_4w(concat_df)\n",
    "    draw_4w_df = concat_4w_df.copy()\n",
    "    draw_4w_df['sequence'] = draw_4w_df.groupby('unique_id').cumcount()+1\n",
    "    save_all_features(output_result_dir, draw_4w_df, concept_dict)\n",
    "\n",
    "    # Normalization (Min/Max Scalar)\n",
    "    concat_df = normalization(concat_df)\n",
    "    concat_df = concat_df.dropna(axis=1)\n",
    "    concat_4w_df = normalization(concat_4w_df)\n",
    "    concat_4w_df = concat_4w_df.dropna(axis=1)\n",
    "\n",
    "    # columns name : concept_id > concept_name\n",
    "    concat_df = concat_df.rename(concept_dict, axis='columns')\n",
    "    concat_4w_df = concat_4w_df.rename(concept_dict, axis='columns')\n",
    "\n",
    "    # Save File\n",
    "    concat_df.to_csv('{}/{}.txt'.format(output_dir, outcome_name), index=False, float_format='%g')\n",
    "    concat_4w_df.to_csv('{}/{}_4w.txt'.format(output_dir, outcome_name), index=False, float_format='%g')\n",
    "\n",
    "    output={}\n",
    "    output['meas_whole_var'] = len(meas_df.concept_id.unique())\n",
    "    output['drug_whole_var'] = len(drug_df.concept_id.unique())\n",
    "    output['proc_whole_var'] = len(proc_df.concept_id.unique())\n",
    "    output['cond_whole_var'] = len(cond_df.concept_id.unique())\n",
    "    output['meas_selected_var'] = len(domain_ids['meas'])\n",
    "    output['drug_selected_var'] = len(domain_ids['drug'])\n",
    "    output['proc_selected_var'] = len(domain_ids['proc'])\n",
    "    output['cond_selected_var'] = len(domain_ids['cond'])\n",
    "    output['nPatient_label1'] = len(concat_df[concat_df[\"label\"] == 1])\n",
    "    output['nPatient_label0'] = len(concat_df[concat_df[\"label\"] == 0])\n",
    "\n",
    "    # print\n",
    "    print(output['meas_whole_var'], output['meas_selected_var'])\n",
    "    print(output['drug_whole_var'], output['drug_selected_var'])\n",
    "    print(output['proc_whole_var'], output['proc_selected_var'])\n",
    "    print(output['cond_whole_var'], output['cond_selected_var'])\n",
    "\n",
    "    out = open('{}/output.txt'.format(output_result_dir),'a')\n",
    "\n",
    "    out.write(str(outcome_name) + '///' )\n",
    "    out.write(str(output['meas_whole_var']) + '///')\n",
    "    out.write(str(output['meas_selected_var']) + '///')\n",
    "    out.write(str(output['drug_whole_var']) + '///')\n",
    "    out.write(str(output['drug_selected_var']) + '///')\n",
    "    out.write(str(output['proc_whole_var']) + '///')\n",
    "    out.write(str(output['proc_selected_var']) + '///')\n",
    "    out.write(str(output['cond_whole_var']) + '///')\n",
    "    out.write(str(output['cond_selected_var']) + '///')\n",
    "    out.write(str(output['nPatient_label1']) + '///')\n",
    "    out.write(str(output['nPatient_label0']) + '\\n')\n",
    "    out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome_name in tqdm(cfg['drug'].keys()) :\n",
    "    try :\n",
    "        runTask(outcome_name)\n",
    "    except :\n",
    "        traceback.print_exc()\n",
    "        log.error(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9045736b69e2f8814b71be39877dcae222bacd6a95a19c9cc1b71f5c99b15c3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
